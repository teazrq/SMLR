<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 26 Principal Component Analysis | Statistical Machine Learning with R</title>
  <meta name="description" content="A Textbook for Statistical Machine Learning Courses at UIUC" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 26 Principal Component Analysis | Statistical Machine Learning with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A Textbook for Statistical Machine Learning Courses at UIUC" />
  <meta name="github-repo" content="teazrq/SMLR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 26 Principal Component Analysis | Statistical Machine Learning with R" />
  
  <meta name="twitter:description" content="A Textbook for Statistical Machine Learning Courses at UIUC" />
  

<meta name="author" content="Ruoqing Zhu, PhD" />


<meta name="date" content="2025-10-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="hierarchical-clustering.html"/>
<link rel="next" href="self-organizing-map.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.33/datatables.js"></script>
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<script src="libs/plotly-binding-4.11.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Machine Learning with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#target-audience"><i class="fa fa-check"></i>Target Audience</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#whats-covered"><i class="fa fa-check"></i>What’s Covered?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="part"><span><b>I Basics Knowledge</b></span></li>
<li class="chapter" data-level="1" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html"><i class="fa fa-check"></i><b>1</b> R and RStudio</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#r-basic"><i class="fa fa-check"></i><b>1.2</b> Resources and Guides</a></li>
<li class="chapter" data-level="1.3" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#basic-mathematical-operations"><i class="fa fa-check"></i><b>1.3</b> Basic Mathematical Operations</a></li>
<li class="chapter" data-level="1.4" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#data-objects"><i class="fa fa-check"></i><b>1.4</b> Data Objects</a></li>
<li class="chapter" data-level="1.5" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#readin-and-save-data"><i class="fa fa-check"></i><b>1.5</b> Readin and save data</a></li>
<li class="chapter" data-level="1.6" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#using-and-defining-functions"><i class="fa fa-check"></i><b>1.6</b> Using and defining functions</a></li>
<li class="chapter" data-level="1.7" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#distribution-and-random-numbers"><i class="fa fa-check"></i><b>1.7</b> Distribution and random numbers</a></li>
<li class="chapter" data-level="1.8" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#using-packages-and-other-resources"><i class="fa fa-check"></i><b>1.8</b> Using packages and other resources</a></li>
<li class="chapter" data-level="1.9" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#practice-questions"><i class="fa fa-check"></i><b>1.9</b> Practice questions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rmarkdown.html"><a href="rmarkdown.html"><i class="fa fa-check"></i><b>2</b> RMarkdown</a>
<ul>
<li class="chapter" data-level="2.1" data-path="rmarkdown.html"><a href="rmarkdown.html#basics-and-resources"><i class="fa fa-check"></i><b>2.1</b> Basics and Resources</a></li>
<li class="chapter" data-level="2.2" data-path="rmarkdown.html"><a href="rmarkdown.html#formatting-text"><i class="fa fa-check"></i><b>2.2</b> Formatting Text</a></li>
<li class="chapter" data-level="2.3" data-path="rmarkdown.html"><a href="rmarkdown.html#adding-r-code"><i class="fa fa-check"></i><b>2.3</b> Adding <code>R</code> Code</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="rmarkdown.html"><a href="rmarkdown.html#r-chunks"><i class="fa fa-check"></i><b>2.3.1</b> <code>R</code> Chunks</a></li>
<li class="chapter" data-level="2.3.2" data-path="rmarkdown.html"><a href="rmarkdown.html#inline-r"><i class="fa fa-check"></i><b>2.3.2</b> Inline <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="rmarkdown.html"><a href="rmarkdown.html#importing-data"><i class="fa fa-check"></i><b>2.4</b> Importing Data</a></li>
<li class="chapter" data-level="2.5" data-path="rmarkdown.html"><a href="rmarkdown.html#working-directory"><i class="fa fa-check"></i><b>2.5</b> Working Directory</a></li>
<li class="chapter" data-level="2.6" data-path="rmarkdown.html"><a href="rmarkdown.html#plotting"><i class="fa fa-check"></i><b>2.6</b> Plotting</a></li>
<li class="chapter" data-level="2.7" data-path="rmarkdown.html"><a href="rmarkdown.html#chunk-options"><i class="fa fa-check"></i><b>2.7</b> Chunk Options</a></li>
<li class="chapter" data-level="2.8" data-path="rmarkdown.html"><a href="rmarkdown.html#adding-math-with-latex"><i class="fa fa-check"></i><b>2.8</b> Adding Math with LaTeX</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="rmarkdown.html"><a href="rmarkdown.html#displaystyle-latex"><i class="fa fa-check"></i><b>2.8.1</b> Displaystyle LaTeX</a></li>
<li class="chapter" data-level="2.8.2" data-path="rmarkdown.html"><a href="rmarkdown.html#inline-latex"><i class="fa fa-check"></i><b>2.8.2</b> Inline LaTex</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="rmarkdown.html"><a href="rmarkdown.html#output-options"><i class="fa fa-check"></i><b>2.9</b> Output Options</a></li>
<li class="chapter" data-level="2.10" data-path="rmarkdown.html"><a href="rmarkdown.html#try-it"><i class="fa fa-check"></i><b>2.10</b> Try It!</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="visual-studio-code.html"><a href="visual-studio-code.html"><i class="fa fa-check"></i><b>3</b> Visual Studio Code</a>
<ul>
<li class="chapter" data-level="3.1" data-path="visual-studio-code.html"><a href="visual-studio-code.html#basics-and-resources-1"><i class="fa fa-check"></i><b>3.1</b> Basics and Resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-algebra-basics.html"><a href="linear-algebra-basics.html"><i class="fa fa-check"></i><b>4</b> Linear Algebra Basics</a>
<ul>
<li class="chapter" data-level="4.1" data-path="linear-algebra-basics.html"><a href="linear-algebra-basics.html#definition"><i class="fa fa-check"></i><b>4.1</b> Definition</a></li>
<li class="chapter" data-level="4.2" data-path="linear-algebra-basics.html"><a href="linear-algebra-basics.html#linear-regression"><i class="fa fa-check"></i><b>4.2</b> Linear Regression</a></li>
<li class="chapter" data-level="4.3" data-path="linear-algebra-basics.html"><a href="linear-algebra-basics.html#matrix-inversion"><i class="fa fa-check"></i><b>4.3</b> Matrix Inversion</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="linear-algebra-basics.html"><a href="linear-algebra-basics.html#linearalgebra-SM"><i class="fa fa-check"></i><b>4.3.1</b> Rank-one Update</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-algebra-basics.html"><a href="linear-algebra-basics.html#rank-k-update"><i class="fa fa-check"></i><b>4.3.2</b> Rank-<span class="math inline">\(k\)</span> Update</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-algebra-basics.html"><a href="linear-algebra-basics.html#times-2-block-matrix-inversion"><i class="fa fa-check"></i><b>4.3.3</b> 2 <span class="math inline">\(\times\)</span> 2 Block Matrix Inversion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="optimization-basics.html"><a href="optimization-basics.html"><i class="fa fa-check"></i><b>5</b> Optimization Basics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="optimization-basics.html"><a href="optimization-basics.html#basic-concept"><i class="fa fa-check"></i><b>5.1</b> Basic Concept</a></li>
<li class="chapter" data-level="5.2" data-path="optimization-basics.html"><a href="optimization-basics.html#global_local"><i class="fa fa-check"></i><b>5.2</b> Global vs. Local Optima</a></li>
<li class="chapter" data-level="5.3" data-path="optimization-basics.html"><a href="optimization-basics.html#example-linear-regression-using-optim"><i class="fa fa-check"></i><b>5.3</b> Example: Linear Regression using <code>optim()</code></a></li>
<li class="chapter" data-level="5.4" data-path="optimization-basics.html"><a href="optimization-basics.html#first-and-second-order-properties"><i class="fa fa-check"></i><b>5.4</b> First and Second Order Properties</a></li>
<li class="chapter" data-level="5.5" data-path="optimization-basics.html"><a href="optimization-basics.html#algorithm"><i class="fa fa-check"></i><b>5.5</b> Algorithm</a></li>
<li class="chapter" data-level="5.6" data-path="optimization-basics.html"><a href="optimization-basics.html#second-order-methods"><i class="fa fa-check"></i><b>5.6</b> Second-order Methods</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="optimization-basics.html"><a href="optimization-basics.html#newtons-method"><i class="fa fa-check"></i><b>5.6.1</b> Newton’s Method</a></li>
<li class="chapter" data-level="5.6.2" data-path="optimization-basics.html"><a href="optimization-basics.html#quasi-newton-methods"><i class="fa fa-check"></i><b>5.6.2</b> Quasi-Newton Methods</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="optimization-basics.html"><a href="optimization-basics.html#first-order-methods"><i class="fa fa-check"></i><b>5.7</b> First-order Methods</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="optimization-basics.html"><a href="optimization-basics.html#gradient-descent"><i class="fa fa-check"></i><b>5.7.1</b> Gradient Descent</a></li>
<li class="chapter" data-level="5.7.2" data-path="optimization-basics.html"><a href="optimization-basics.html#gradient-descent-example-linear-regression"><i class="fa fa-check"></i><b>5.7.2</b> Gradient Descent Example: Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="optimization-basics.html"><a href="optimization-basics.html#coordinate"><i class="fa fa-check"></i><b>5.8</b> Coordinate Descent</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="optimization-basics.html"><a href="optimization-basics.html#coordinate-descent-example-linear-regression"><i class="fa fa-check"></i><b>5.8.1</b> Coordinate Descent Example: Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="optimization-basics.html"><a href="optimization-basics.html#stocastic-gradient-descent"><i class="fa fa-check"></i><b>5.9</b> Stocastic Gradient Descent</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="optimization-basics.html"><a href="optimization-basics.html#mini-batch-stocastic-gradient-descent"><i class="fa fa-check"></i><b>5.9.1</b> Mini-batch Stocastic Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="optimization-basics.html"><a href="optimization-basics.html#lagrangian-multiplier-for-constrained-problems"><i class="fa fa-check"></i><b>5.10</b> Lagrangian Multiplier for Constrained Problems</a></li>
</ul></li>
<li class="part"><span><b>II Linear and Penalized Linear Models</b></span></li>
<li class="chapter" data-level="6" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html"><i class="fa fa-check"></i><b>6</b> Linear Regression and Model Selection</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#example-real-estate-data"><i class="fa fa-check"></i><b>6.1</b> Example: real estate data</a></li>
<li class="chapter" data-level="6.2" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#notation-and-basic-properties"><i class="fa fa-check"></i><b>6.2</b> Notation and Basic Properties</a></li>
<li class="chapter" data-level="6.3" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#using-the-lm-function"><i class="fa fa-check"></i><b>6.3</b> Using the <code>lm()</code> Function</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#adding-covariates"><i class="fa fa-check"></i><b>6.3.1</b> Adding Covariates</a></li>
<li class="chapter" data-level="6.3.2" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#categorical-variables"><i class="fa fa-check"></i><b>6.3.2</b> Categorical Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#model-selection-criteria"><i class="fa fa-check"></i><b>6.4</b> Model Selection Criteria</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#using-marrows-c_p"><i class="fa fa-check"></i><b>6.4.1</b> Using Marrows’ <span class="math inline">\(C_p\)</span></a></li>
<li class="chapter" data-level="6.4.2" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#using-aic-and-bic"><i class="fa fa-check"></i><b>6.4.2</b> Using AIC and BIC</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#model-selection-algorithms"><i class="fa fa-check"></i><b>6.5</b> Model Selection Algorithms</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#best-subset-selection-with-leaps"><i class="fa fa-check"></i><b>6.5.1</b> Best Subset Selection with <code>leaps</code></a></li>
<li class="chapter" data-level="6.5.2" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#step-wise-regression-using-step"><i class="fa fa-check"></i><b>6.5.2</b> Step-wise regression using <code>step()</code></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="linear-regression-and-model-selection.html"><a href="linear-regression-and-model-selection.html#marrows-cp"><i class="fa fa-check"></i><b>6.6</b> Derivation of Marrows’ <span class="math inline">\(C_p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>7</b> Ridge Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ridge-regression.html"><a href="ridge-regression.html#motivation-correlated-variables-and-convexity"><i class="fa fa-check"></i><b>7.1</b> Motivation: Correlated Variables and Convexity</a></li>
<li class="chapter" data-level="7.2" data-path="ridge-regression.html"><a href="ridge-regression.html#ridge-penalty-and-the-reduced-variation"><i class="fa fa-check"></i><b>7.2</b> Ridge Penalty and the Reduced Variation</a></li>
<li class="chapter" data-level="7.3" data-path="ridge-regression.html"><a href="ridge-regression.html#bias-and-variance-of-ridge-regression"><i class="fa fa-check"></i><b>7.3</b> Bias and Variance of Ridge Regression</a></li>
<li class="chapter" data-level="7.4" data-path="ridge-regression.html"><a href="ridge-regression.html#degrees-of-freedom"><i class="fa fa-check"></i><b>7.4</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="7.5" data-path="ridge-regression.html"><a href="ridge-regression.html#using-the-lm.ridge-function"><i class="fa fa-check"></i><b>7.5</b> Using the <code>lm.ridge()</code> function</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="ridge-regression.html"><a href="ridge-regression.html#scaling-issue"><i class="fa fa-check"></i><b>7.5.1</b> Scaling Issue</a></li>
<li class="chapter" data-level="7.5.2" data-path="ridge-regression.html"><a href="ridge-regression.html#multiple-lambda-values"><i class="fa fa-check"></i><b>7.5.2</b> Multiple <span class="math inline">\(\lambda\)</span> values</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ridge-regression.html"><a href="ridge-regression.html#cross-validation"><i class="fa fa-check"></i><b>7.6</b> Cross-validation</a></li>
<li class="chapter" data-level="7.7" data-path="ridge-regression.html"><a href="ridge-regression.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>7.7</b> Leave-one-out cross-validation</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="ridge-regression.html"><a href="ridge-regression.html#generalized-cross-validation"><i class="fa fa-check"></i><b>7.7.1</b> Generalized cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="ridge-regression.html"><a href="ridge-regression.html#the-glmnet-package"><i class="fa fa-check"></i><b>7.8</b> The <code>glmnet</code> package</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="ridge-regression.html"><a href="ridge-regression.html#scaling-issue-1"><i class="fa fa-check"></i><b>7.8.1</b> Scaling Issue</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>8</b> Lasso</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lasso.html"><a href="lasso.html#one-variable-lasso-and-shrinkage"><i class="fa fa-check"></i><b>8.1</b> One-Variable Lasso and Shrinkage</a></li>
<li class="chapter" data-level="8.2" data-path="lasso.html"><a href="lasso.html#constrained-optimization-view"><i class="fa fa-check"></i><b>8.2</b> Constrained Optimization View</a></li>
<li class="chapter" data-level="8.3" data-path="lasso.html"><a href="lasso.html#the-solution-path"><i class="fa fa-check"></i><b>8.3</b> The Solution Path</a></li>
<li class="chapter" data-level="8.4" data-path="lasso.html"><a href="lasso.html#path-wise-coordinate-descent"><i class="fa fa-check"></i><b>8.4</b> Path-wise Coordinate Descent</a></li>
<li class="chapter" data-level="8.5" data-path="lasso.html"><a href="lasso.html#using-the-glmnet-package"><i class="fa fa-check"></i><b>8.5</b> Using the <code>glmnet</code> package</a></li>
<li class="chapter" data-level="8.6" data-path="lasso.html"><a href="lasso.html#elastic-net"><i class="fa fa-check"></i><b>8.6</b> Elastic-Net</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="spline.html"><a href="spline.html"><i class="fa fa-check"></i><b>9</b> Spline</a>
<ul>
<li class="chapter" data-level="9.1" data-path="spline.html"><a href="spline.html#using-linear-models-for-nonlinear-trends"><i class="fa fa-check"></i><b>9.1</b> Using Linear models for Nonlinear Trends</a></li>
<li class="chapter" data-level="9.2" data-path="spline.html"><a href="spline.html#a-motivating-example-and-polynomials"><i class="fa fa-check"></i><b>9.2</b> A Motivating Example and Polynomials</a></li>
<li class="chapter" data-level="9.3" data-path="spline.html"><a href="spline.html#piecewise-polynomials"><i class="fa fa-check"></i><b>9.3</b> Piecewise Polynomials</a></li>
<li class="chapter" data-level="9.4" data-path="spline.html"><a href="spline.html#splines"><i class="fa fa-check"></i><b>9.4</b> Splines</a></li>
<li class="chapter" data-level="9.5" data-path="spline.html"><a href="spline.html#spline-basis"><i class="fa fa-check"></i><b>9.5</b> Spline Basis</a></li>
<li class="chapter" data-level="9.6" data-path="spline.html"><a href="spline.html#natural-cubic-spline"><i class="fa fa-check"></i><b>9.6</b> Natural Cubic Spline</a></li>
<li class="chapter" data-level="9.7" data-path="spline.html"><a href="spline.html#smoothing-spline"><i class="fa fa-check"></i><b>9.7</b> Smoothing Spline</a></li>
<li class="chapter" data-level="9.8" data-path="spline.html"><a href="spline.html#fitting-smoothing-splines"><i class="fa fa-check"></i><b>9.8</b> Fitting Smoothing Splines</a></li>
<li class="chapter" data-level="9.9" data-path="spline.html"><a href="spline.html#extending-splines-to-multiple-varibles"><i class="fa fa-check"></i><b>9.9</b> Extending Splines to Multiple Varibles</a></li>
</ul></li>
<li class="part"><span><b>III Linear Classification Models</b></span></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#modeling-binary-outcomes"><i class="fa fa-check"></i><b>10.1</b> Modeling Binary Outcomes</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#example-cleveland-clinic-heart-disease-data"><i class="fa fa-check"></i><b>10.2</b> Example: Cleveland Clinic Heart Disease Data</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#interpretation-of-the-parameters"><i class="fa fa-check"></i><b>10.3</b> Interpretation of the Parameters</a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression.html"><a href="logistic-regression.html#solving-a-logistic-regression"><i class="fa fa-check"></i><b>10.4</b> Solving a Logistic Regression</a></li>
<li class="chapter" data-level="10.5" data-path="logistic-regression.html"><a href="logistic-regression.html#example-south-africa-heart-data"><i class="fa fa-check"></i><b>10.5</b> Example: South Africa Heart Data</a></li>
<li class="chapter" data-level="10.6" data-path="logistic-regression.html"><a href="logistic-regression.html#penalized-logistic-regression"><i class="fa fa-check"></i><b>10.6</b> Penalized Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html"><i class="fa fa-check"></i><b>11</b> Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="11.1" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#bayes-rule"><i class="fa fa-check"></i><b>11.1</b> Bayes Rule</a></li>
<li class="chapter" data-level="11.2" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#example-linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>11.2</b> Example: Linear Discriminant Analysis (LDA)</a></li>
<li class="chapter" data-level="11.3" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>11.3</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="11.4" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#example-quadratic-discriminant-analysis-qda"><i class="fa fa-check"></i><b>11.4</b> Example: Quadratic Discriminant Analysis (QDA)</a></li>
<li class="chapter" data-level="11.5" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>11.5</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="11.6" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#example-the-hand-written-digit-data"><i class="fa fa-check"></i><b>11.6</b> Example: the Hand Written Digit Data</a></li>
</ul></li>
<li class="part"><span><b>IV Local Averaging and Kernel Smoothing</b></span></li>
<li class="chapter" data-level="12" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html"><i class="fa fa-check"></i><b>12</b> K-Neariest Neighber</a>
<ul>
<li class="chapter" data-level="12.1" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#definition-1"><i class="fa fa-check"></i><b>12.1</b> Definition</a></li>
<li class="chapter" data-level="12.2" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#tuning-k"><i class="fa fa-check"></i><b>12.2</b> Tuning <span class="math inline">\(k\)</span></a></li>
<li class="chapter" data-level="12.3" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#the-bias-variance-trade-off"><i class="fa fa-check"></i><b>12.3</b> The Bias-variance Trade-off</a></li>
<li class="chapter" data-level="12.4" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#knn-for-classification"><i class="fa fa-check"></i><b>12.4</b> KNN for Classification</a></li>
<li class="chapter" data-level="12.5" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#example-1-an-artificial-data"><i class="fa fa-check"></i><b>12.5</b> Example 1: An artificial data</a></li>
<li class="chapter" data-level="12.6" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#degrees-of-freedom-1"><i class="fa fa-check"></i><b>12.6</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="12.7" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#tuning-with-the-caret-package"><i class="fa fa-check"></i><b>12.7</b> Tuning with the <code>caret</code> Package</a></li>
<li class="chapter" data-level="12.8" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#distance-measures"><i class="fa fa-check"></i><b>12.8</b> Distance Measures</a></li>
<li class="chapter" data-level="12.9" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#nn-error-bound"><i class="fa fa-check"></i><b>12.9</b> 1NN Error Bound</a></li>
<li class="chapter" data-level="12.10" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#example-2-handwritten-digit-data"><i class="fa fa-check"></i><b>12.10</b> Example 2: Handwritten Digit Data</a></li>
<li class="chapter" data-level="12.11" data-path="k-neariest-neighber.html"><a href="k-neariest-neighber.html#curse-of-dimensionality"><i class="fa fa-check"></i><b>12.11</b> Curse of Dimensionality</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html"><i class="fa fa-check"></i><b>13</b> Kernel Smoothing</a>
<ul>
<li class="chapter" data-level="13.1" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#knn-vs.-kernel"><i class="fa fa-check"></i><b>13.1</b> KNN vs. Kernel</a></li>
<li class="chapter" data-level="13.2" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#kernel-density-estimations"><i class="fa fa-check"></i><b>13.2</b> Kernel Density Estimations</a></li>
<li class="chapter" data-level="13.3" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#expectation-of-the-parzen-estimator"><i class="fa fa-check"></i><b>13.3</b> Expectation of the Parzen estimator</a></li>
<li class="chapter" data-level="13.4" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#gaussian-kernel-regression"><i class="fa fa-check"></i><b>13.4</b> Gaussian Kernel Regression</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>13.4.1</b> Bias-variance Trade-off</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#choice-of-kernel-functions"><i class="fa fa-check"></i><b>13.5</b> Choice of Kernel Functions</a></li>
<li class="chapter" data-level="13.6" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#local-linear-regression"><i class="fa fa-check"></i><b>13.6</b> Local Linear Regression</a></li>
<li class="chapter" data-level="13.7" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#local-polynomial-regression"><i class="fa fa-check"></i><b>13.7</b> Local Polynomial Regression</a></li>
<li class="chapter" data-level="13.8" data-path="kernel-smoothing.html"><a href="kernel-smoothing.html#r-implementations"><i class="fa fa-check"></i><b>13.8</b> R Implementations</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="nonpara.html"><a href="nonpara.html"><i class="fa fa-check"></i><b>14</b> Nonparemetric Estimation Rates</a>
<ul>
<li class="chapter" data-level="14.1" data-path="nonpara.html"><a href="nonpara.html#kernel-density-estimation"><i class="fa fa-check"></i><b>14.1</b> Kernel Density Estimation</a></li>
<li class="chapter" data-level="14.2" data-path="nonpara.html"><a href="nonpara.html#the-effect-of-smoothness"><i class="fa fa-check"></i><b>14.2</b> The Effect of Smoothness</a></li>
<li class="chapter" data-level="14.3" data-path="nonpara.html"><a href="nonpara.html#the-effect-of-dimensionality"><i class="fa fa-check"></i><b>14.3</b> The Effect of Dimensionality</a></li>
<li class="chapter" data-level="14.4" data-path="nonpara.html"><a href="nonpara.html#nadaraya-watson-regression-estimator"><i class="fa fa-check"></i><b>14.4</b> Nadaraya-Watson Regression Estimator</a></li>
</ul></li>
<li class="part"><span><b>V Kernel Machines</b></span></li>
<li class="chapter" data-level="15" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html"><i class="fa fa-check"></i><b>15</b> Reproducing Kernel Hilbert Space</a>
<ul>
<li class="chapter" data-level="15.1" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#the-motivation"><i class="fa fa-check"></i><b>15.1</b> The Motivation</a></li>
<li class="chapter" data-level="15.2" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#hilbert-space-preliminaries"><i class="fa fa-check"></i><b>15.2</b> Hilbert Space Preliminaries</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#the-space-of-square-integrable-functions"><i class="fa fa-check"></i><b>15.2.1</b> The Space of Square-Integrable Functions</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#a-kernel-function"><i class="fa fa-check"></i><b>15.3</b> A Kernel Function</a></li>
<li class="chapter" data-level="15.4" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#a-space-of-functions"><i class="fa fa-check"></i><b>15.4</b> A Space of Functions</a></li>
<li class="chapter" data-level="15.5" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#the-inner-product"><i class="fa fa-check"></i><b>15.5</b> The Inner Product</a></li>
<li class="chapter" data-level="15.6" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#the-rkhs"><i class="fa fa-check"></i><b>15.6</b> The RKHS</a></li>
<li class="chapter" data-level="15.7" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#the-reproducing-property"><i class="fa fa-check"></i><b>15.7</b> The Reproducing Property</a></li>
<li class="chapter" data-level="15.8" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#smoothness"><i class="fa fa-check"></i><b>15.8</b> Smoothness</a></li>
<li class="chapter" data-level="15.9" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#the-moorearonszajn-theorem"><i class="fa fa-check"></i><b>15.9</b> The Moore–Aronszajn Theorem</a></li>
<li class="chapter" data-level="15.10" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#examples"><i class="fa fa-check"></i><b>15.10</b> Examples</a>
<ul>
<li class="chapter" data-level="15.10.1" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#brownian-motion-kernel"><i class="fa fa-check"></i><b>15.10.1</b> Brownian Motion Kernel</a></li>
<li class="chapter" data-level="15.10.2" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#non-positive-definite-kernel"><i class="fa fa-check"></i><b>15.10.2</b> Non-positive Definite Kernel</a></li>
<li class="chapter" data-level="15.10.3" data-path="reproducing-kernel-hilbert-space.html"><a href="reproducing-kernel-hilbert-space.html#defining-new-kernels"><i class="fa fa-check"></i><b>15.10.3</b> Defining New Kernels</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="kernel-ridge-regression.html"><a href="kernel-ridge-regression.html"><i class="fa fa-check"></i><b>16</b> Kernel Ridge Regression</a>
<ul>
<li class="chapter" data-level="16.1" data-path="kernel-ridge-regression.html"><a href="kernel-ridge-regression.html#linear-regression-as-a-constraint-optimization"><i class="fa fa-check"></i><b>16.1</b> Linear Regression as a Constraint Optimization</a></li>
<li class="chapter" data-level="16.2" data-path="kernel-ridge-regression.html"><a href="kernel-ridge-regression.html#the-kernel-ridge-regression"><i class="fa fa-check"></i><b>16.2</b> The Kernel Ridge Regression</a></li>
<li class="chapter" data-level="16.3" data-path="kernel-ridge-regression.html"><a href="kernel-ridge-regression.html#ridge-regression-as-a-linear-kernel-model"><i class="fa fa-check"></i><b>16.3</b> Ridge Regression as a Linear Kernel Model</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>17</b> Support Vector Machines</a>
<ul>
<li class="chapter" data-level="17.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#maximum-margin-classifier"><i class="fa fa-check"></i><b>17.1</b> Maximum-margin Classifier</a></li>
<li class="chapter" data-level="17.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#linearly-separable-svm"><i class="fa fa-check"></i><b>17.2</b> Linearly Separable SVM</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#from-primal-to-dual"><i class="fa fa-check"></i><b>17.2.1</b> From Primal to Dual</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#linearly-non-separable-svm-with-slack-variables"><i class="fa fa-check"></i><b>17.3</b> Linearly Non-separable SVM with Slack Variables</a></li>
<li class="chapter" data-level="17.4" data-path="support-vector-machines.html"><a href="support-vector-machines.html#example-saheart-data"><i class="fa fa-check"></i><b>17.4</b> Example: <code>SAheart</code> Data</a></li>
<li class="chapter" data-level="17.5" data-path="support-vector-machines.html"><a href="support-vector-machines.html#nonlinear-svm-via-kernel-trick"><i class="fa fa-check"></i><b>17.5</b> Nonlinear SVM via Kernel Trick</a></li>
<li class="chapter" data-level="17.6" data-path="support-vector-machines.html"><a href="support-vector-machines.html#example-mixture.example-data"><i class="fa fa-check"></i><b>17.6</b> Example: <code>mixture.example</code> Data</a></li>
<li class="chapter" data-level="17.7" data-path="support-vector-machines.html"><a href="support-vector-machines.html#svm-as-a-penalized-model"><i class="fa fa-check"></i><b>17.7</b> SVM as a Penalized Model</a></li>
<li class="chapter" data-level="17.8" data-path="support-vector-machines.html"><a href="support-vector-machines.html#kernel-and-feature-maps-another-example"><i class="fa fa-check"></i><b>17.8</b> Kernel and Feature Maps: Another Example</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="the-representer-theorem.html"><a href="the-representer-theorem.html"><i class="fa fa-check"></i><b>18</b> The Representer Theorem</a>
<ul>
<li class="chapter" data-level="18.1" data-path="the-representer-theorem.html"><a href="the-representer-theorem.html#the-representer-theorem-1"><i class="fa fa-check"></i><b>18.1</b> The Representer Theorem</a></li>
<li class="chapter" data-level="18.2" data-path="the-representer-theorem.html"><a href="the-representer-theorem.html#notes-on-application"><i class="fa fa-check"></i><b>18.2</b> Notes on Application</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="support-vector-regression.html"><a href="support-vector-regression.html"><i class="fa fa-check"></i><b>19</b> Support Vector Regression</a>
<ul>
<li class="chapter" data-level="19.1" data-path="support-vector-regression.html"><a href="support-vector-regression.html#the-epsilon-insensitive-loss"><i class="fa fa-check"></i><b>19.1</b> The <span class="math inline">\(\epsilon\)</span>-insensitive Loss</a></li>
<li class="chapter" data-level="19.2" data-path="support-vector-regression.html"><a href="support-vector-regression.html#primal-and-dual-formulation-of-svr"><i class="fa fa-check"></i><b>19.2</b> Primal and Dual Formulation of SVR</a></li>
<li class="chapter" data-level="19.3" data-path="support-vector-regression.html"><a href="support-vector-regression.html#penalized-svr-with-rkhs"><i class="fa fa-check"></i><b>19.3</b> Penalized SVR with RKHS</a></li>
</ul></li>
<li class="part"><span><b>VI Trees and Ensembles</b></span></li>
<li class="chapter" data-level="20" data-path="classification-and-regression-trees.html"><a href="classification-and-regression-trees.html"><i class="fa fa-check"></i><b>20</b> Classification and Regression Trees</a>
<ul>
<li class="chapter" data-level="20.1" data-path="classification-and-regression-trees.html"><a href="classification-and-regression-trees.html#example-classification-tree"><i class="fa fa-check"></i><b>20.1</b> Example: Classification Tree</a></li>
<li class="chapter" data-level="20.2" data-path="classification-and-regression-trees.html"><a href="classification-and-regression-trees.html#splitting-a-node"><i class="fa fa-check"></i><b>20.2</b> Splitting a Node</a></li>
<li class="chapter" data-level="20.3" data-path="classification-and-regression-trees.html"><a href="classification-and-regression-trees.html#regression-trees"><i class="fa fa-check"></i><b>20.3</b> Regression Trees</a></li>
<li class="chapter" data-level="20.4" data-path="classification-and-regression-trees.html"><a href="classification-and-regression-trees.html#predicting-a-target-point"><i class="fa fa-check"></i><b>20.4</b> Predicting a Target Point</a></li>
<li class="chapter" data-level="20.5" data-path="classification-and-regression-trees.html"><a href="classification-and-regression-trees.html#tuning-a-tree-model"><i class="fa fa-check"></i><b>20.5</b> Tuning a Tree Model</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>21</b> Random Forests</a>
<ul>
<li class="chapter" data-level="21.1" data-path="random-forests.html"><a href="random-forests.html#bagging-predictors"><i class="fa fa-check"></i><b>21.1</b> Bagging Predictors</a></li>
<li class="chapter" data-level="21.2" data-path="random-forests.html"><a href="random-forests.html#random-forests-1"><i class="fa fa-check"></i><b>21.2</b> Random Forests</a></li>
<li class="chapter" data-level="21.3" data-path="random-forests.html"><a href="random-forests.html#kernel-view-of-random-forests"><i class="fa fa-check"></i><b>21.3</b> Kernel view of Random Forests</a></li>
<li class="chapter" data-level="21.4" data-path="random-forests.html"><a href="random-forests.html#variable-importance"><i class="fa fa-check"></i><b>21.4</b> Variable Importance</a></li>
<li class="chapter" data-level="21.5" data-path="random-forests.html"><a href="random-forests.html#adaptiveness-of-random-forest-kernel"><i class="fa fa-check"></i><b>21.5</b> Adaptiveness of Random Forest Kernel</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="adaboost.html"><a href="adaboost.html"><i class="fa fa-check"></i><b>22</b> AdaBoost</a>
<ul>
<li class="chapter" data-level="22.1" data-path="adaboost.html"><a href="adaboost.html#the-algorithm"><i class="fa fa-check"></i><b>22.1</b> The Algorithm</a></li>
<li class="chapter" data-level="22.2" data-path="adaboost.html"><a href="adaboost.html#training-error-bound"><i class="fa fa-check"></i><b>22.2</b> Training Error Bound</a></li>
<li class="chapter" data-level="22.3" data-path="adaboost.html"><a href="adaboost.html#the-stagewise-additive-model-and-probability-calibration"><i class="fa fa-check"></i><b>22.3</b> The Stagewise Additive Model and Probability Calibration</a></li>
<li class="chapter" data-level="22.4" data-path="adaboost.html"><a href="adaboost.html#tuning-the-number-of-trees"><i class="fa fa-check"></i><b>22.4</b> Tuning the Number of Trees</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="gradient-boosting-machines.html"><a href="gradient-boosting-machines.html"><i class="fa fa-check"></i><b>23</b> Gradient Boosting Machines</a>
<ul>
<li class="chapter" data-level="23.1" data-path="gradient-boosting-machines.html"><a href="gradient-boosting-machines.html#motivation-lasso-as-boosting"><i class="fa fa-check"></i><b>23.1</b> Motivation: Lasso as Boosting</a></li>
<li class="chapter" data-level="23.2" data-path="gradient-boosting-machines.html"><a href="gradient-boosting-machines.html#gradient-boosting"><i class="fa fa-check"></i><b>23.2</b> Gradient Boosting</a></li>
<li class="chapter" data-level="23.3" data-path="gradient-boosting-machines.html"><a href="gradient-boosting-machines.html#gradient-boosting-with-general-loss"><i class="fa fa-check"></i><b>23.3</b> Gradient Boosting with General Loss</a></li>
<li class="chapter" data-level="23.4" data-path="gradient-boosting-machines.html"><a href="gradient-boosting-machines.html#logistic-link"><i class="fa fa-check"></i><b>23.4</b> Logistic Link</a></li>
<li class="chapter" data-level="23.5" data-path="gradient-boosting-machines.html"><a href="gradient-boosting-machines.html#xgboost"><i class="fa fa-check"></i><b>23.5</b> xgboost</a></li>
</ul></li>
<li class="part"><span><b>VII Unsupervised Learning</b></span></li>
<li class="chapter" data-level="24" data-path="k-means.html"><a href="k-means.html"><i class="fa fa-check"></i><b>24</b> K-Means</a>
<ul>
<li class="chapter" data-level="24.1" data-path="k-means.html"><a href="k-means.html#basic-concepts"><i class="fa fa-check"></i><b>24.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="24.2" data-path="k-means.html"><a href="k-means.html#example-1-iris-data"><i class="fa fa-check"></i><b>24.2</b> Example 1: <code>iris</code> data</a></li>
<li class="chapter" data-level="24.3" data-path="k-means.html"><a href="k-means.html#example-2-clustering-of-image-pixels"><i class="fa fa-check"></i><b>24.3</b> Example 2: clustering of image pixels</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>25</b> Hierarchical Clustering</a>
<ul>
<li class="chapter" data-level="25.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#basic-concepts-1"><i class="fa fa-check"></i><b>25.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="25.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#example-1-iris-data-1"><i class="fa fa-check"></i><b>25.2</b> Example 1: <code>iris</code> data</a></li>
<li class="chapter" data-level="25.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#example-2-rna-expression-data"><i class="fa fa-check"></i><b>25.3</b> Example 2: RNA Expression Data</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>26</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="26.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#basic-concepts-2"><i class="fa fa-check"></i><b>26.1</b> Basic Concepts</a>
<ul>
<li class="chapter" data-level="26.1.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#note-scaling"><i class="fa fa-check"></i><b>26.1.1</b> Note: Scaling</a></li>
</ul></li>
<li class="chapter" data-level="26.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#example-1-iris-data-2"><i class="fa fa-check"></i><b>26.2</b> Example 1: <code>iris</code> Data</a></li>
<li class="chapter" data-level="26.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#example-2-handwritten-digits"><i class="fa fa-check"></i><b>26.3</b> Example 2: Handwritten Digits</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="self-organizing-map.html"><a href="self-organizing-map.html"><i class="fa fa-check"></i><b>27</b> Self-Organizing Map</a>
<ul>
<li class="chapter" data-level="27.1" data-path="self-organizing-map.html"><a href="self-organizing-map.html#basic-concepts-3"><i class="fa fa-check"></i><b>27.1</b> Basic Concepts</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="spectral-clustering.html"><a href="spectral-clustering.html"><i class="fa fa-check"></i><b>28</b> Spectral Clustering</a>
<ul>
<li class="chapter" data-level="28.1" data-path="spectral-clustering.html"><a href="spectral-clustering.html#an-example"><i class="fa fa-check"></i><b>28.1</b> An Example</a></li>
<li class="chapter" data-level="28.2" data-path="spectral-clustering.html"><a href="spectral-clustering.html#adjacency-matrix"><i class="fa fa-check"></i><b>28.2</b> Adjacency Matrix</a></li>
<li class="chapter" data-level="28.3" data-path="spectral-clustering.html"><a href="spectral-clustering.html#laplacian-matrix"><i class="fa fa-check"></i><b>28.3</b> Laplacian Matrix</a></li>
<li class="chapter" data-level="28.4" data-path="spectral-clustering.html"><a href="spectral-clustering.html#derivation-of-the-feature-embedding"><i class="fa fa-check"></i><b>28.4</b> Derivation of the Feature Embedding</a></li>
<li class="chapter" data-level="28.5" data-path="spectral-clustering.html"><a href="spectral-clustering.html#feature-embedding"><i class="fa fa-check"></i><b>28.5</b> Feature Embedding</a></li>
<li class="chapter" data-level="28.6" data-path="spectral-clustering.html"><a href="spectral-clustering.html#clustering-with-embedded-features"><i class="fa fa-check"></i><b>28.6</b> Clustering with Embedded Features</a></li>
<li class="chapter" data-level="28.7" data-path="spectral-clustering.html"><a href="spectral-clustering.html#normalized-graph-laplacian"><i class="fa fa-check"></i><b>28.7</b> Normalized Graph Laplacian</a></li>
<li class="chapter" data-level="28.8" data-path="spectral-clustering.html"><a href="spectral-clustering.html#using-a-different-adjacency-matrix"><i class="fa fa-check"></i><b>28.8</b> Using a Different Adjacency Matrix</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="uniform-manifold-approximation-and-projection.html"><a href="uniform-manifold-approximation-and-projection.html"><i class="fa fa-check"></i><b>29</b> Uniform Manifold Approximation and Projection</a>
<ul>
<li class="chapter" data-level="29.1" data-path="uniform-manifold-approximation-and-projection.html"><a href="uniform-manifold-approximation-and-projection.html#an-example-1"><i class="fa fa-check"></i><b>29.1</b> An Example</a></li>
<li class="chapter" data-level="29.2" data-path="uniform-manifold-approximation-and-projection.html"><a href="uniform-manifold-approximation-and-projection.html#tuning"><i class="fa fa-check"></i><b>29.2</b> Tuning</a></li>
<li class="chapter" data-level="29.3" data-path="uniform-manifold-approximation-and-projection.html"><a href="uniform-manifold-approximation-and-projection.html#another-example"><i class="fa fa-check"></i><b>29.3</b> Another Example</a></li>
</ul></li>
<li class="part"><span><b>VIII Reference</b></span></li>
<li class="chapter" data-level="30" data-path="reference.html"><a href="reference.html"><i class="fa fa-check"></i><b>30</b> Reference</a></li>
<li class="divider"></li>
<li><a href="https://github.com/teazrq/SMLR" target="blank">&copy; 2023 Ruoqing Zhu</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Machine Learning with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="principal-component-analysis" class="section level1 hasAnchor" number="26">
<h1><span class="header-section-number">Chapter 26</span> Principal Component Analysis<a href="principal-component-analysis.html#principal-component-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="basic-concepts-2" class="section level2 hasAnchor" number="26.1">
<h2><span class="header-section-number">26.1</span> Basic Concepts<a href="principal-component-analysis.html#basic-concepts-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Principal Component Analysis (PCA) is arguably the most commonly used approach for dimension reduction and visualization. The idea is to capture major signals of variation in a dataset. A nice demonstration of the search of direction is provided at this <a href="https://www.r-bloggers.com/principal-component-analysis-in-r/">r-bloggers</a> site:</p>
<center>
<img src="images/PCA2.gif" />
</center>
<p>Let’s look at a two-dimensional case, we are trying to find a line (direction) on this plain, such that if all points are projected onto this line, their coordinates have the largest variance, compared with any other line. The following code is used to generate a set of observations.</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="principal-component-analysis.html#cb197-1" tabindex="-1"></a>  <span class="co"># generate some random data from a 2-dimensional normal distribution. </span></span>
<span id="cb197-2"><a href="principal-component-analysis.html#cb197-2" tabindex="-1"></a>  <span class="fu">library</span>(MASS)</span>
<span id="cb197-3"><a href="principal-component-analysis.html#cb197-3" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb197-4"><a href="principal-component-analysis.html#cb197-4" tabindex="-1"></a>  </span>
<span id="cb197-5"><a href="principal-component-analysis.html#cb197-5" tabindex="-1"></a>  n <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb197-6"><a href="principal-component-analysis.html#cb197-6" tabindex="-1"></a>  Sigma <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">0.5</span>, <span class="sc">-</span><span class="fl">0.65</span>, <span class="sc">-</span><span class="fl">0.65</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb197-7"><a href="principal-component-analysis.html#cb197-7" tabindex="-1"></a>  x_org <span class="ot">=</span> <span class="fu">mvrnorm</span>(n, <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), Sigma)</span>
<span id="cb197-8"><a href="principal-component-analysis.html#cb197-8" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">scale</span>(x_org, <span class="at">scale =</span> <span class="cn">FALSE</span>, <span class="at">center =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="principal-component-analysis.html#cb198-1" tabindex="-1"></a>  <span class="fu">plot</span>(x, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>), <span class="at">ylim=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>), </span>
<span id="cb198-2"><a href="principal-component-analysis.html#cb198-2" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="fl">0.75</span>)</span>
<span id="cb198-3"><a href="principal-component-analysis.html#cb198-3" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb198-4"><a href="principal-component-analysis.html#cb198-4" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-323-1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>Let’ start with finding a direction to project all the observations onto. And we want this projection to have the largest variation. Of course the direction that goes along the spread of the data would be the best choice for the purpose of large variance.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="principal-component-analysis.html#cb199-1" tabindex="-1"></a>  <span class="fu">plot</span>(x, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>), <span class="at">ylim=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="fl">0.75</span>)</span>
<span id="cb199-2"><a href="principal-component-analysis.html#cb199-2" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb199-3"><a href="principal-component-analysis.html#cb199-3" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb199-4"><a href="principal-component-analysis.html#cb199-4" tabindex="-1"></a></span>
<span id="cb199-5"><a href="principal-component-analysis.html#cb199-5" tabindex="-1"></a>  <span class="co"># This line is obtained from performing PCA</span></span>
<span id="cb199-6"><a href="principal-component-analysis.html#cb199-6" tabindex="-1"></a>  pc1 <span class="ot">=</span> <span class="fu">princomp</span>(x)<span class="sc">$</span>loadings[,<span class="dv">1</span>]</span>
<span id="cb199-7"><a href="principal-component-analysis.html#cb199-7" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> pc1[<span class="dv">2</span>]<span class="sc">/</span>pc1[<span class="dv">1</span>], <span class="at">col =</span> <span class="st">&quot;deepskyblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-324-1.png" width="40%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="principal-component-analysis.html#cb200-1" tabindex="-1"></a>  </span>
<span id="cb200-2"><a href="principal-component-analysis.html#cb200-2" tabindex="-1"></a>  <span class="co"># The direction </span></span>
<span id="cb200-3"><a href="principal-component-analysis.html#cb200-3" tabindex="-1"></a>  pc1</span>
<span id="cb200-4"><a href="principal-component-analysis.html#cb200-4" tabindex="-1"></a><span class="do">## [1]  0.5659608 -0.8244322</span></span></code></pre></div>
<p>Once we have the first direction, we can also remove the projection from the original covariates, and search for a direction <span class="math inline">\(\mathbf{v}_2\)</span> that is orthogonal to <span class="math inline">\(\mathbf{v}_1\)</span>, with <span class="math inline">\(\mathbf{v}_1^\text{T}\mathbf{v}_2 = 0\)</span>, such that it contains large variation of <span class="math inline">\(\mathbf{X}\)</span>.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="principal-component-analysis.html#cb201-1" tabindex="-1"></a>  <span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="fl">0.3</span>, <span class="fl">0.3</span>))</span>
<span id="cb201-2"><a href="principal-component-analysis.html#cb201-2" tabindex="-1"></a>  <span class="fu">plot</span>(x, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>), <span class="at">ylim=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="fl">0.5</span>)</span>
<span id="cb201-3"><a href="principal-component-analysis.html#cb201-3" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb201-4"><a href="principal-component-analysis.html#cb201-4" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb201-5"><a href="principal-component-analysis.html#cb201-5" tabindex="-1"></a></span>
<span id="cb201-6"><a href="principal-component-analysis.html#cb201-6" tabindex="-1"></a>  <span class="co"># largest PC </span></span>
<span id="cb201-7"><a href="principal-component-analysis.html#cb201-7" tabindex="-1"></a>  pc1 <span class="ot">=</span> <span class="fu">princomp</span>(x)<span class="sc">$</span>loadings[,<span class="dv">1</span>]</span>
<span id="cb201-8"><a href="principal-component-analysis.html#cb201-8" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> pc1[<span class="dv">2</span>]<span class="sc">/</span>pc1[<span class="dv">1</span>], <span class="at">col =</span> <span class="st">&quot;deepskyblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span>
<span id="cb201-9"><a href="principal-component-analysis.html#cb201-9" tabindex="-1"></a></span>
<span id="cb201-10"><a href="principal-component-analysis.html#cb201-10" tabindex="-1"></a>  <span class="co"># second largest PC</span></span>
<span id="cb201-11"><a href="principal-component-analysis.html#cb201-11" tabindex="-1"></a>  pc2 <span class="ot">=</span> <span class="fu">princomp</span>(x)<span class="sc">$</span>loadings[,<span class="dv">2</span>]</span>
<span id="cb201-12"><a href="principal-component-analysis.html#cb201-12" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> pc2[<span class="dv">2</span>]<span class="sc">/</span>pc2[<span class="dv">1</span>], <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-325-1.png" width="40%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="principal-component-analysis.html#cb202-1" tabindex="-1"></a>  </span>
<span id="cb202-2"><a href="principal-component-analysis.html#cb202-2" tabindex="-1"></a>  pc2</span>
<span id="cb202-3"><a href="principal-component-analysis.html#cb202-3" tabindex="-1"></a><span class="do">## [1] 0.8244322 0.5659608</span></span>
<span id="cb202-4"><a href="principal-component-analysis.html#cb202-4" tabindex="-1"></a>  <span class="fu">t</span>(pc1) <span class="sc">%*%</span> pc2</span>
<span id="cb202-5"><a href="principal-component-analysis.html#cb202-5" tabindex="-1"></a><span class="do">##      [,1]</span></span>
<span id="cb202-6"><a href="principal-component-analysis.html#cb202-6" tabindex="-1"></a><span class="do">## [1,]    0</span></span></code></pre></div>
<p>We can also see how much variation these two directions accounts for in the original data. The following shows the corresponding standard deviation.</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="principal-component-analysis.html#cb203-1" tabindex="-1"></a>  <span class="fu">princomp</span>(x)<span class="sc">$</span>sdev</span>
<span id="cb203-2"><a href="principal-component-analysis.html#cb203-2" tabindex="-1"></a><span class="do">##    Comp.1    Comp.2 </span></span>
<span id="cb203-3"><a href="principal-component-analysis.html#cb203-3" tabindex="-1"></a><span class="do">## 1.0748243 0.2206133</span></span></code></pre></div>
<p>Formally, we can generalized this to <span class="math inline">\(\mathbf{X}\)</span> with any dimensions. And the key tool is to perform the singular value decomposition (SVD):</p>
<p><span class="math display">\[\mathbf{X}= \mathbf{U}\mathbf{D}\mathbf{V}^\text{T}\]</span>
The <span class="math inline">\(\mathbf{V}\)</span> matrix here corresponds to the directions we found. Hence, <span class="math inline">\(\mathbf{v}_1\)</span> is its first column, <span class="math inline">\(\mathbf{v}_1\)</span> is its second column, etc.. <span class="math inline">\(\mathbf{D}\)</span> is a diagonal matrix ordered from the largest to the smallest values, correspond to the standard deviation of the spreads. And <span class="math inline">\(\mathbf{U}\)</span> represents the coordinates once we project <span class="math inline">\(\mathbf{X}\)</span> onto those directions. An alternative way to understand this is by matrix approximation, if we want to find a rank-1 matrix that best approximate <span class="math inline">\(\mathbf{X}\)</span> with the Frobenius norm, we optimize</p>
<p><span class="math display">\[\text{minimize} \quad \lVert \mathbf{X}- \mathbf{u}_1 d_1 \mathbf{v}_1^\text{T}\rVert_2^2\]</span></p>
<p>This can be generalized into any dimensional problem. Another alternative formulation is to use eigen-decomposition of <span class="math inline">\(\mathbf{X}^\text{T}\mathbf{X}\)</span>, which can be written as</p>
<p><span class="math display">\[\mathbf{X}^\text{T}\mathbf{X}= \mathbf{V}\mathbf{D}\mathbf{U}^\text{T}\mathbf{U}\mathbf{D}\mathbf{V}^\text{T}= \mathbf{V}\mathbf{D}^2 \mathbf{V}^\text{T}\]</span></p>
<p>But one thing we usually need to take care of is the centering issue. This is why we used <code>scale()</code> function at the beginning. However, we only center, but not scale the data. If we do not center, then the first principal component (PC) could be a direction that points to the center of the data. Note that when <span class="math inline">\(\mathbf{X}\)</span> is already centered, <span class="math inline">\(\mathbf{X}^\text{T}\mathbf{X}\)</span> is the covariance matrix. Hence PCA is also performing eigen-decomposition to the covariance matrix.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="principal-component-analysis.html#cb204-1" tabindex="-1"></a>    <span class="fu">plot</span>(x_org, <span class="at">main =</span> <span class="st">&quot;Before Centering&quot;</span>, </span>
<span id="cb204-2"><a href="principal-component-analysis.html#cb204-2" tabindex="-1"></a>         <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">ylim=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="fl">0.5</span>)</span>
<span id="cb204-3"><a href="principal-component-analysis.html#cb204-3" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb204-4"><a href="principal-component-analysis.html#cb204-4" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb204-5"><a href="principal-component-analysis.html#cb204-5" tabindex="-1"></a>    </span>
<span id="cb204-6"><a href="principal-component-analysis.html#cb204-6" tabindex="-1"></a>    <span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="fl">0.3</span>))</span>
<span id="cb204-7"><a href="principal-component-analysis.html#cb204-7" tabindex="-1"></a>    <span class="fu">plot</span>(x, <span class="at">main =</span> <span class="st">&quot;After Centering&quot;</span>, </span>
<span id="cb204-8"><a href="principal-component-analysis.html#cb204-8" tabindex="-1"></a>         <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">ylim=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex =</span> <span class="fl">0.5</span>)</span>
<span id="cb204-9"><a href="principal-component-analysis.html#cb204-9" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb204-10"><a href="principal-component-analysis.html#cb204-10" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)    </span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-328-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Finally, for any dimensional data <span class="math inline">\(\mathbf{X}\)</span>, we usually visualize them in the first two directions, or three. Note that the coordinates on the PC’s can be obtained using either the <code>scores</code> (<span class="math inline">\(\mathbf{U}\)</span>) in the fitted object of <code>princomp</code>, or simply multiply the original data matrix by the loading matrix <span class="math inline">\(\mathbf{V}\)</span>.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="principal-component-analysis.html#cb205-1" tabindex="-1"></a>    pcafit <span class="ot">&lt;-</span> <span class="fu">princomp</span>(x)</span>
<span id="cb205-2"><a href="principal-component-analysis.html#cb205-2" tabindex="-1"></a></span>
<span id="cb205-3"><a href="principal-component-analysis.html#cb205-3" tabindex="-1"></a>    <span class="co"># the new coordinates on PC&#39;s</span></span>
<span id="cb205-4"><a href="principal-component-analysis.html#cb205-4" tabindex="-1"></a>    <span class="fu">head</span>(pcafit<span class="sc">$</span>scores)</span>
<span id="cb205-5"><a href="principal-component-analysis.html#cb205-5" tabindex="-1"></a><span class="do">##           Comp.1      Comp.2</span></span>
<span id="cb205-6"><a href="principal-component-analysis.html#cb205-6" tabindex="-1"></a><span class="do">## [1,]  0.88434533  0.13503607</span></span>
<span id="cb205-7"><a href="principal-component-analysis.html#cb205-7" tabindex="-1"></a><span class="do">## [2,] -0.08990294 -0.01851954</span></span>
<span id="cb205-8"><a href="principal-component-analysis.html#cb205-8" tabindex="-1"></a><span class="do">## [3,]  1.13589963  0.20234582</span></span>
<span id="cb205-9"><a href="principal-component-analysis.html#cb205-9" tabindex="-1"></a><span class="do">## [4,] -1.78763374 -0.04571218</span></span>
<span id="cb205-10"><a href="principal-component-analysis.html#cb205-10" tabindex="-1"></a><span class="do">## [5,] -0.26536435  0.14271170</span></span>
<span id="cb205-11"><a href="principal-component-analysis.html#cb205-11" tabindex="-1"></a><span class="do">## [6,]  1.11779894 -0.41759594</span></span>
<span id="cb205-12"><a href="principal-component-analysis.html#cb205-12" tabindex="-1"></a>    </span>
<span id="cb205-13"><a href="principal-component-analysis.html#cb205-13" tabindex="-1"></a>    <span class="co"># direct calculation based on projection </span></span>
<span id="cb205-14"><a href="principal-component-analysis.html#cb205-14" tabindex="-1"></a>    <span class="fu">head</span>(x <span class="sc">%*%</span> pcafit<span class="sc">$</span>loadings)</span>
<span id="cb205-15"><a href="principal-component-analysis.html#cb205-15" tabindex="-1"></a><span class="do">##           Comp.1      Comp.2</span></span>
<span id="cb205-16"><a href="principal-component-analysis.html#cb205-16" tabindex="-1"></a><span class="do">## [1,]  0.88434533  0.13503607</span></span>
<span id="cb205-17"><a href="principal-component-analysis.html#cb205-17" tabindex="-1"></a><span class="do">## [2,] -0.08990294 -0.01851954</span></span>
<span id="cb205-18"><a href="principal-component-analysis.html#cb205-18" tabindex="-1"></a><span class="do">## [3,]  1.13589963  0.20234582</span></span>
<span id="cb205-19"><a href="principal-component-analysis.html#cb205-19" tabindex="-1"></a><span class="do">## [4,] -1.78763374 -0.04571218</span></span>
<span id="cb205-20"><a href="principal-component-analysis.html#cb205-20" tabindex="-1"></a><span class="do">## [5,] -0.26536435  0.14271170</span></span>
<span id="cb205-21"><a href="principal-component-analysis.html#cb205-21" tabindex="-1"></a><span class="do">## [6,]  1.11779894 -0.41759594</span></span>
<span id="cb205-22"><a href="principal-component-analysis.html#cb205-22" tabindex="-1"></a></span>
<span id="cb205-23"><a href="principal-component-analysis.html#cb205-23" tabindex="-1"></a>    <span class="co"># visualize the data on the PCs</span></span>
<span id="cb205-24"><a href="principal-component-analysis.html#cb205-24" tabindex="-1"></a>    <span class="co"># Note that the both axies are scaled </span></span>
<span id="cb205-25"><a href="principal-component-analysis.html#cb205-25" tabindex="-1"></a>    <span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>, <span class="fl">4.2</span>, <span class="fl">0.3</span>, <span class="fl">0.3</span>))</span>
<span id="cb205-26"><a href="principal-component-analysis.html#cb205-26" tabindex="-1"></a>    <span class="fu">plot</span>(pcafit<span class="sc">$</span>scores[,<span class="dv">1</span>], pcafit<span class="sc">$</span>scores[,<span class="dv">2</span>], <span class="at">xlab =</span> <span class="st">&quot;First PC&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Second PC&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">cex.lab =</span> <span class="fl">1.5</span>)</span>
<span id="cb205-27"><a href="principal-component-analysis.html#cb205-27" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;deepskyblue&quot;</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span>
<span id="cb205-28"><a href="principal-component-analysis.html#cb205-28" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;darkorange&quot;</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-330-1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>There are many different functions in <code>R</code> that performs PCA. <code>princomp</code> and <code>prcomp</code> are the most popular ones.</p>
<div id="note-scaling" class="section level3 hasAnchor" number="26.1.1">
<h3><span class="header-section-number">26.1.1</span> Note: Scaling<a href="principal-component-analysis.html#note-scaling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You should always center the variables when performing PCA, however, whether to use scaling (force each variable to have a standard deviation of 1) depends on the particular application. When you have variables that are extremely disproportionate, e.g., age vs. RNA expression, scaling should be used. This is to prevent some variables from dominating the PC loadings due to their large scales. When all the variables are of the similar type, e.g., color intensities of pixels in a figure, it is better to use the original scale. This is because the variables with larger variations may carry more signal. Scaling may lose that information.</p>
</div>
</div>
<div id="example-1-iris-data-2" class="section level2 hasAnchor" number="26.2">
<h2><span class="header-section-number">26.2</span> Example 1: <code>iris</code> Data<a href="principal-component-analysis.html#example-1-iris-data-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We use the <code>iris</code> data again. All four variables are considered in this analysis. We plot the first and second PC directions.</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="principal-component-analysis.html#cb206-1" tabindex="-1"></a>    iris_pc <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb206-2"><a href="principal-component-analysis.html#cb206-2" tabindex="-1"></a>    <span class="fu">library</span>(ggplot2)</span>
<span id="cb206-3"><a href="principal-component-analysis.html#cb206-3" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(iris_pc<span class="sc">$</span>x), <span class="fu">aes</span>(<span class="at">x=</span>PC1, <span class="at">y=</span>PC2)) <span class="sc">+</span> </span>
<span id="cb206-4"><a href="principal-component-analysis.html#cb206-4" tabindex="-1"></a>        <span class="fu">geom_point</span>(<span class="at">color=</span><span class="fu">c</span>(<span class="st">&quot;chartreuse4&quot;</span>, <span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;deepskyblue&quot;</span>)[iris<span class="sc">$</span>Species], <span class="at">size =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-331-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>One may be interested in plotting all pair-wise direction to see if lower PC’s provide useful information.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="principal-component-analysis.html#cb207-1" tabindex="-1"></a>    <span class="fu">pairs</span>(iris_pc<span class="sc">$</span>x, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;chartreuse4&quot;</span>, <span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;deepskyblue&quot;</span>)[iris<span class="sc">$</span>Species], <span class="at">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-332-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>However, usually, the lower PC’s are less informative. This can also be speculated from the eigenvalue plot, which shows how influential each PC is.</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="principal-component-analysis.html#cb208-1" tabindex="-1"></a>    <span class="fu">plot</span>(iris_pc, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">main =</span> <span class="st">&quot;Iris PCA Variance&quot;</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-333-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Feature contributions to the PC can be accessed through the magnitude of the loadings. This table shows that <code>Petal.Length</code> is the most influential variable on the first PC, with loading <span class="math inline">\(\approx 0.8567\)</span>.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="principal-component-analysis.html#cb209-1" tabindex="-1"></a>    iris_pc<span class="sc">$</span>rotation</span>
<span id="cb209-2"><a href="principal-component-analysis.html#cb209-2" tabindex="-1"></a><span class="do">##                      PC1         PC2         PC3        PC4</span></span>
<span id="cb209-3"><a href="principal-component-analysis.html#cb209-3" tabindex="-1"></a><span class="do">## Sepal.Length  0.36138659 -0.65658877  0.58202985  0.3154872</span></span>
<span id="cb209-4"><a href="principal-component-analysis.html#cb209-4" tabindex="-1"></a><span class="do">## Sepal.Width  -0.08452251 -0.73016143 -0.59791083 -0.3197231</span></span>
<span id="cb209-5"><a href="principal-component-analysis.html#cb209-5" tabindex="-1"></a><span class="do">## Petal.Length  0.85667061  0.17337266 -0.07623608 -0.4798390</span></span>
<span id="cb209-6"><a href="principal-component-analysis.html#cb209-6" tabindex="-1"></a><span class="do">## Petal.Width   0.35828920  0.07548102 -0.54583143  0.7536574</span></span></code></pre></div>
<p>We can further visualize this on a plot. This can be helpful when the number of variables is large.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="principal-component-analysis.html#cb210-1" tabindex="-1"></a>    features <span class="ot">=</span> <span class="fu">row.names</span>(iris_pc<span class="sc">$</span>rotation)</span>
<span id="cb210-2"><a href="principal-component-analysis.html#cb210-2" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(iris_pc<span class="sc">$</span>rotation), <span class="fu">aes</span>(<span class="at">x=</span>PC1, <span class="at">y=</span>PC2, <span class="at">label=</span>features,<span class="at">color=</span>features)) <span class="sc">+</span> </span>
<span id="cb210-3"><a href="principal-component-analysis.html#cb210-3" tabindex="-1"></a>        <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span> <span class="fu">geom_text</span>(<span class="at">size=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-335-1.png" width="45%" style="display: block; margin: auto;" /></p>
</div>
<div id="example-2-handwritten-digits" class="section level2 hasAnchor" number="26.3">
<h2><span class="header-section-number">26.3</span> Example 2: Handwritten Digits<a href="principal-component-analysis.html#example-2-handwritten-digits" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The handwritten zip code digits data contains 7291 training data and 2007 testing data. Each image is a <span class="math inline">\(16 \times 16\)</span>-pixel gray-scale image. Hence they are converted to a vector of 256 variables.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="principal-component-analysis.html#cb211-1" tabindex="-1"></a>    <span class="fu">library</span>(ElemStatLearn)</span>
<span id="cb211-2"><a href="principal-component-analysis.html#cb211-2" tabindex="-1"></a>    <span class="co"># Handwritten Digit Recognition Data</span></span>
<span id="cb211-3"><a href="principal-component-analysis.html#cb211-3" tabindex="-1"></a>    <span class="co"># the first column is the true digit</span></span>
<span id="cb211-4"><a href="principal-component-analysis.html#cb211-4" tabindex="-1"></a>    <span class="fu">dim</span>(zip.train)</span>
<span id="cb211-5"><a href="principal-component-analysis.html#cb211-5" tabindex="-1"></a><span class="do">## [1] 7291  257</span></span></code></pre></div>
<p>Here is a sample of some images:</p>
<p><img src="SMLR_files/figure-html/unnamed-chunk-337-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Let’s do a simpler task, using just three letters: 1, 4 and 8.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="principal-component-analysis.html#cb212-1" tabindex="-1"></a>    zip.sub <span class="ot">=</span> zip.train[zip.train[,<span class="dv">1</span>] <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">8</span>), <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb212-2"><a href="principal-component-analysis.html#cb212-2" tabindex="-1"></a>    zip.sub.truth <span class="ot">=</span> <span class="fu">as.factor</span>(zip.train[zip.train[,<span class="dv">1</span>] <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">8</span>), <span class="dv">1</span>])</span>
<span id="cb212-3"><a href="principal-component-analysis.html#cb212-3" tabindex="-1"></a>    <span class="fu">dim</span>(zip.sub)</span>
<span id="cb212-4"><a href="principal-component-analysis.html#cb212-4" tabindex="-1"></a><span class="do">## [1] 2199  256</span></span>
<span id="cb212-5"><a href="principal-component-analysis.html#cb212-5" tabindex="-1"></a>    zip_pc <span class="ot">=</span> <span class="fu">prcomp</span>(zip.sub)</span>
<span id="cb212-6"><a href="principal-component-analysis.html#cb212-6" tabindex="-1"></a>    <span class="fu">plot</span>(zip_pc, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">main =</span> <span class="st">&quot;Digits 1, 4, and 8: PCA Variance&quot;</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-338-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>The eigenvalue results suggest that the first two principal components are much more influential than the rest. A pair-wise PC plot of the first four PC’s may further confirm that speculation.</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="principal-component-analysis.html#cb213-1" tabindex="-1"></a>    <span class="fu">pairs</span>(zip_pc<span class="sc">$</span>x[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;chartreuse4&quot;</span>, <span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;deepskyblue&quot;</span>)[zip.sub.truth], <span class="at">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-339-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Let’s look at the first two PCs more closely. Even without knowing the true class (no colors) we can still vaguely see 3 clusters.</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="principal-component-analysis.html#cb214-1" tabindex="-1"></a>    <span class="fu">library</span>(ggplot2)</span>
<span id="cb214-2"><a href="principal-component-analysis.html#cb214-2" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(zip_pc<span class="sc">$</span>x), <span class="fu">aes</span>(<span class="at">x=</span>PC1, <span class="at">y=</span>PC2)) <span class="sc">+</span> </span>
<span id="cb214-3"><a href="principal-component-analysis.html#cb214-3" tabindex="-1"></a>        <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-340-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Finally, let’s briefly look at the results of PCA for all 10 different digits. Of course, more PC’s are needed for this task. You can also plot other PC’s to get more information.</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="principal-component-analysis.html#cb215-1" tabindex="-1"></a>    <span class="fu">library</span>(colorspace)</span>
<span id="cb215-2"><a href="principal-component-analysis.html#cb215-2" tabindex="-1"></a></span>
<span id="cb215-3"><a href="principal-component-analysis.html#cb215-3" tabindex="-1"></a>    zip_pc <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(zip.train)</span>
<span id="cb215-4"><a href="principal-component-analysis.html#cb215-4" tabindex="-1"></a></span>
<span id="cb215-5"><a href="principal-component-analysis.html#cb215-5" tabindex="-1"></a>    <span class="fu">plot</span>(zip_pc, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">main =</span> <span class="st">&quot;All Digits: PCA Variance&quot;</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-341-1.png" width="45%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="principal-component-analysis.html#cb216-1" tabindex="-1"></a></span>
<span id="cb216-2"><a href="principal-component-analysis.html#cb216-2" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="fu">prcomp</span>(zip.train)<span class="sc">$</span>x), <span class="fu">aes</span>(<span class="at">x=</span>PC1, <span class="at">y=</span>PC2)) <span class="sc">+</span> </span>
<span id="cb216-3"><a href="principal-component-analysis.html#cb216-3" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">rainbow_hcl</span>(<span class="dv">10</span>)[zip.train[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">1</span>], <span class="at">size =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="SMLR_files/figure-html/unnamed-chunk-341-2.png" width="45%" style="display: block; margin: auto;" /></p>

<div style="display:none;">
<!-- Conflict \def\bf{\mathbf{f}} -->
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hierarchical-clustering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="self-organizing-map.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "sepia",
    "family": "serif",
    "size": 1
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
